{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall protobuf\n",
        "#!pip install protobuf==3.20.3"
      ],
      "metadata": {
        "id": "KsuiHs-mdmM4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tensorflow"
      ],
      "metadata": {
        "id": "3N3kII3bURpa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "source": [
        "#!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.17.1\n",
        "!pip install tf-models-official==2.17.0\n",
        "#!pip uninstall protobuf\n",
        "!pip install protobuf==3.20.3"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "slGKDHIIla3O",
        "outputId": "16b5d034-bcce-4ec9-9b6e-5f9dcae2cc4b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.17.1 in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.1) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.17.1) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow==2.17.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow==2.17.1) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow==2.17.1) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.1) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.1) (0.1.2)\n",
            "Collecting tf-models-official==2.17.0\n",
            "  Using cached tf_models_official-2.17.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (3.0.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (11.1.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (2.160.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (4.2.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (1.6.17)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (1.26.4)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (4.11.0.86)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (2.0.8)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (6.0.2)\n",
            "Collecting sacrebleu (from tf-models-official==2.17.0)\n",
            "  Using cached sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (1.14.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (0.2.0)\n",
            "Collecting seqeval (from tf-models-official==2.17.0)\n",
            "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (4.9.8)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.17.0)\n",
            "  Using cached tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Collecting tensorflow-text~=2.17.0 (from tf-models-official==2.17.0)\n",
            "  Using cached tensorflow_text-2.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow~=2.17.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (2.17.1)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (2.18.0)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official==2.17.0) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.17.0) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.17.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.17.0) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.17.0) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.17.0) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official==2.17.0) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official==2.17.0) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official==2.17.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official==2.17.0) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official==2.17.0) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official==2.17.0) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official==2.17.0) (6.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official==2.17.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.22.0->tf-models-official==2.17.0) (2025.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.17.0->tf-models-official==2.17.0) (0.37.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.17.0) (0.1.9)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.16.0 (from tf-models-official==2.17.0)\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official==2.17.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official==2.17.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official==2.17.0) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official==2.17.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->tf-models-official==2.17.0) (3.2.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official==2.17.0) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official==2.17.0) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official==2.17.0) (4.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official==2.17.0) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official==2.17.0) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official==2.17.0) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official==2.17.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->tf-models-official==2.17.0) (5.3.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval->tf-models-official==2.17.0) (1.6.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official==2.17.0) (0.7.1)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.17.0) (1.12.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official==2.17.0) (2.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official==2.17.0) (18.1.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official==2.17.0) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official==2.17.0) (1.16.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official==2.17.0) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow~=2.17.0->tf-models-official==2.17.0) (0.45.1)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization>=0.4.1->tf-models-official==2.17.0) (25.2.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.17.0) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.17.0) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.17.0) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.17.0) (3.21.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.17.0) (1.69.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.17.0) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.17.0) (5.5.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow~=2.17.0->tf-models-official==2.17.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow~=2.17.0->tf-models-official==2.17.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow~=2.17.0->tf-models-official==2.17.0) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.17.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.17.0) (3.10)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.17.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.17.0) (3.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow~=2.17.0->tf-models-official==2.17.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow~=2.17.0->tf-models-official==2.17.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow~=2.17.0->tf-models-official==2.17.0) (3.1.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.17.0) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.17.0) (1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->tf-models-official==2.17.0) (0.16)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow~=2.17.0->tf-models-official==2.17.0)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow~=2.17.0->tf-models-official==2.17.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow~=2.17.0->tf-models-official==2.17.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow~=2.17.0->tf-models-official==2.17.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow~=2.17.0->tf-models-official==2.17.0) (0.1.2)\n",
            "Downloading tf_models_official-2.17.0-py2.py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=c640c171c2171b54dea666063a568cc183549c9f06610ee3fe7a99c21d97fc8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: protobuf, colorama, tensorflow-model-optimization, sacrebleu, seqeval, tf-keras, tensorflow-text, tf-models-official\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.18.0\n",
            "    Uninstalling tf_keras-2.18.0:\n",
            "      Successfully uninstalled tf_keras-2.18.0\n",
            "  Attempting uninstall: tensorflow-text\n",
            "    Found existing installation: tensorflow-text 2.18.1\n",
            "    Uninstalling tensorflow-text-2.18.1:\n",
            "      Successfully uninstalled tensorflow-text-2.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 protobuf-4.25.6 sacrebleu-2.5.1 seqeval-1.2.2 tensorflow-model-optimization-0.8.0 tensorflow-text-2.17.0 tf-keras-2.17.0 tf-models-official-2.17.0\n",
            "Collecting protobuf==3.20.3\n",
            "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.17.0 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "0bb2e51d3173498387c4ff39f404b086"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from object_detection.utils import label_map_util, visualization_utils as vis_util\n",
        "import os\n",
        "import urllib.request\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import string_int_label_map_pb2\n",
        "import requests # Import requests library\n",
        "\n",
        "# Download the pre-trained model (SSD MobileNet v2 trained on COCO)\n",
        "#MODEL_NAME = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
        "MODEL_NAME = 'faster_rcnn_inception_v2_coco_2017_11_08'\n",
        "MODEL_FILE = tf.keras.utils.get_file(MODEL_NAME + '.tar.gz',\n",
        "                                     'http://download.tensorflow.org/models/object_detection/{}.tar.gz'.format(MODEL_NAME),\n",
        "                                     untar=True)\n",
        "\n",
        "# Load the model into TensorFlow\n",
        "# Search for the 'saved_model' directory within the extracted archive\n",
        "PATH_TO_CKPT = MODEL_FILE + '/saved_model'\n",
        "for root, dirs, files in os.walk(MODEL_FILE):\n",
        "    if 'saved_model' in dirs:\n",
        "        PATH_TO_CKPT = os.path.join(root, 'saved_model')\n",
        "        break  # Stop searching once found\n",
        "\n",
        "detection_model = tf.saved_model.load(PATH_TO_CKPT)\n",
        "\n",
        "# Load the COCO labels\n",
        "# Updated URL to a publicly accessible raw file on GitHub\n",
        "PATH_TO_LABELS = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "\n",
        "# Download the label map file using requests instead of urllib.request\n",
        "# This is because urllib might have issues with some firewalls or security settings\n",
        "response = requests.get(PATH_TO_LABELS)\n",
        "response.raise_for_status()  # Raise an exception for bad status codes (like 403)\n",
        "label_map_string = response.text  # Get the content as text\n",
        "\n",
        "\n",
        "# Parse the label map string\n",
        "label_map = string_int_label_map_pb2.StringIntLabelMap()\n",
        "text_format.Merge(label_map_string, label_map)\n",
        "\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=90, use_display_name=True)\n",
        "category_index = {item['id']: item for item in categories}\n",
        "\n",
        "# Replace this URL with your image URL\n",
        "image_url = \"https://raw.githubusercontent.com/geoffswc/UCSF-Research-AI-Symposium-2025/main/cartoon.png\"\n",
        "#image_url = \"https://raw.githubusercontent.com/geoffswc/UCSF-Research-AI-Symposium-2025/main/metadata.png\"\n",
        "# Download and read the image\n",
        "image_path = urllib.request.urlretrieve(image_url, 'image.png')[0]\n",
        "image_np = cv2.imread(image_path)\n",
        "image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert image to tensor and run the detection\n",
        "input_tensor = tf.convert_to_tensor(image_np)\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# Perform detection\n",
        "output_dict = detection_model.signatures['serving_default'](input_tensor)\n",
        "\n",
        "# Extract useful information (boxes, classes, and scores)\n",
        "boxes = output_dict['detection_boxes'][0].numpy()\n",
        "classes = output_dict['detection_classes'][0].numpy().astype(np.int64)\n",
        "scores = output_dict['detection_scores'][0].numpy()\n",
        "\n",
        "print(\"printing\")\n",
        "\n",
        "# Print the detected labels and their confidence scores\n",
        "for i in range(len(classes)):\n",
        "  if scores[i] > 0.01:\n",
        "    label = category_index[classes[i]]['name']\n",
        "    print(f\"Label: {label}, Confidence: {scores[i]:.2f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EkrFcRcXj3a0",
        "outputId": "48d82423-a8e5-40b1-b9f5-b37ddadfd139"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printing\n",
            "Label: person, Confidence: 0.94\n",
            "Label: person, Confidence: 0.87\n",
            "Label: tv, Confidence: 0.47\n",
            "Label: bottle, Confidence: 0.39\n",
            "Label: tv, Confidence: 0.33\n",
            "Label: clock, Confidence: 0.30\n",
            "Label: book, Confidence: 0.20\n",
            "Label: book, Confidence: 0.19\n",
            "Label: person, Confidence: 0.14\n",
            "Label: refrigerator, Confidence: 0.12\n",
            "Label: clock, Confidence: 0.12\n",
            "Label: person, Confidence: 0.10\n",
            "Label: refrigerator, Confidence: 0.10\n",
            "Label: tv, Confidence: 0.08\n",
            "Label: tv, Confidence: 0.07\n",
            "Label: laptop, Confidence: 0.06\n",
            "Label: book, Confidence: 0.06\n",
            "Label: tv, Confidence: 0.06\n",
            "Label: book, Confidence: 0.06\n",
            "Label: scissors, Confidence: 0.06\n",
            "Label: clock, Confidence: 0.05\n",
            "Label: scissors, Confidence: 0.04\n",
            "Label: tv, Confidence: 0.04\n",
            "Label: bottle, Confidence: 0.04\n",
            "Label: train, Confidence: 0.03\n",
            "Label: book, Confidence: 0.03\n",
            "Label: book, Confidence: 0.03\n",
            "Label: tv, Confidence: 0.03\n",
            "Label: person, Confidence: 0.03\n",
            "Label: bus, Confidence: 0.03\n",
            "Label: book, Confidence: 0.03\n",
            "Label: person, Confidence: 0.02\n",
            "Label: microwave, Confidence: 0.02\n",
            "Label: microwave, Confidence: 0.02\n",
            "Label: person, Confidence: 0.02\n",
            "Label: person, Confidence: 0.02\n",
            "Label: book, Confidence: 0.02\n",
            "Label: laptop, Confidence: 0.02\n",
            "Label: person, Confidence: 0.02\n",
            "Label: book, Confidence: 0.02\n",
            "Label: knife, Confidence: 0.02\n",
            "Label: umbrella, Confidence: 0.02\n",
            "Label: tv, Confidence: 0.02\n",
            "Label: scissors, Confidence: 0.02\n",
            "Label: tv, Confidence: 0.02\n",
            "Label: person, Confidence: 0.01\n",
            "Label: tennis racket, Confidence: 0.01\n",
            "Label: book, Confidence: 0.01\n",
            "Label: person, Confidence: 0.01\n",
            "Label: surfboard, Confidence: 0.01\n",
            "Label: book, Confidence: 0.01\n",
            "Label: person, Confidence: 0.01\n",
            "Label: clock, Confidence: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from object_detection.utils import label_map_util, visualization_utils as vis_util\n",
        "import os\n",
        "import urllib.request\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import string_int_label_map_pb2\n",
        "import requests  # Import requests library\n",
        "\n",
        "# Download the pre-trained model (Faster R-CNN Inception v2)\n",
        "MODEL_NAME = 'faster_rcnn_inception_v2_coco_2017_11_08'\n",
        "MODEL_FILE = tf.keras.utils.get_file(MODEL_NAME + '.tar.gz',\n",
        "                                     'http://download.tensorflow.org/models/object_detection/{}.tar.gz'.format(MODEL_NAME),\n",
        "                                     untar=True)\n",
        "\n",
        "# Load the model into TensorFlow\n",
        "PATH_TO_CKPT = MODEL_FILE + '/saved_model'\n",
        "for root, dirs, files in os.walk(MODEL_FILE):\n",
        "    if 'saved_model' in dirs:\n",
        "        PATH_TO_CKPT = os.path.join(root, 'saved_model')\n",
        "        break  # Stop searching once found\n",
        "\n",
        "detection_model = tf.saved_model.load(PATH_TO_CKPT)\n",
        "\n",
        "# Load the COCO labels\n",
        "PATH_TO_LABELS = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "\n",
        "# Download the label map file using requests\n",
        "response = requests.get(PATH_TO_LABELS)\n",
        "response.raise_for_status()  # Raise an exception for bad status codes (like 403)\n",
        "label_map_string = response.text  # Get the content as text\n",
        "\n",
        "# Parse the label map string\n",
        "label_map = string_int_label_map_pb2.StringIntLabelMap()\n",
        "text_format.Merge(label_map_string, label_map)\n",
        "\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=90, use_display_name=True)\n",
        "category_index = {item['id']: item for item in categories}\n",
        "\n",
        "# Replace this URL with your image URL\n",
        "image_url = \"https://raw.githubusercontent.com/geoffswc/UCSF-Research-AI-Symposium-2025/main/cartoon.png\"\n",
        "# Download and read the image\n",
        "image_path = urllib.request.urlretrieve(image_url, 'image.png')[0]\n",
        "image_np = cv2.imread(image_path)\n",
        "image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert image to tensor and run the detection\n",
        "input_tensor = tf.convert_to_tensor(image_np)\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# Perform detection\n",
        "output_dict = detection_model.signatures['serving_default'](input_tensor)\n",
        "\n",
        "# Extract useful information (boxes, classes, and scores)\n",
        "boxes = output_dict['detection_boxes'][0].numpy()\n",
        "classes = output_dict['detection_classes'][0].numpy().astype(np.int64)\n",
        "scores = output_dict['detection_scores'][0].numpy()\n",
        "\n",
        "# Filter and display the results visually\n",
        "for i in range(len(classes)):\n",
        "    if scores[i] > 0.25:\n",
        "        # Get the label and bounding box coordinates\n",
        "        label = category_index[classes[i]]['name']\n",
        "\n",
        "        print(f\"Label: {label}, Confidence: {scores[i]:.2f}\")\n",
        "        box = boxes[i]\n",
        "\n",
        "        # Draw bounding box\n",
        "        ymin, xmin, ymax, xmax = box\n",
        "        (left, right, top, bottom) = (xmin * image_np.shape[1], xmax * image_np.shape[1],\n",
        "                                      ymin * image_np.shape[0], ymax * image_np.shape[0])\n",
        "\n",
        "        # Draw the box and label on the image\n",
        "        image_np = cv2.rectangle(image_np, (int(left), int(top)), (int(right), int(bottom)), (255, 0, 0), 2)\n",
        "        image_np = cv2.putText(image_np, f\"{label}: {scores[i]:.2f}\", (int(left), int(top)-10),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "# Save the image with bounding boxes and labels\n",
        "output_image_path = '/content/output_image.png'\n",
        "cv2.imwrite(output_image_path, cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Provide a link to download the image\n",
        "from google.colab import files\n",
        "files.download(output_image_path)\n",
        "\n",
        "print(f\"Image with bounding boxes saved to {output_image_path} and ready for download.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "iZApdTup1O1S",
        "outputId": "4037d507-9e6b-40ca-cc57-90d29784505b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: person, Confidence: 0.94\n",
            "Label: person, Confidence: 0.87\n",
            "Label: tv, Confidence: 0.47\n",
            "Label: bottle, Confidence: 0.39\n",
            "Label: tv, Confidence: 0.33\n",
            "Label: clock, Confidence: 0.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_74832879-a92a-41c1-afe5-ce1d9ea79142\", \"output_image.png\", 5746290)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image with bounding boxes saved to /content/output_image.png and ready for download.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(output_image_path)"
      ],
      "metadata": {
        "id": "Pl51jKYX4cf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in category_index.values():\n",
        "    print(f\"{item['id']}. {item['name']}\")"
      ],
      "metadata": {
        "id": "X-Ug2RRD4c1c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}